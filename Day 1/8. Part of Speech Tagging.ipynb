{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f6b1535-c86a-445e-820e-997933db2b2e",
   "metadata": {},
   "source": [
    "# Parts of Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e10ae13-d388-4c09-952d-2dc68ba38ff7",
   "metadata": {},
   "source": [
    "**Parts of Speech (POS)** are categories that words can belong to based on their function in a sentence. Each part of speech plays a specific role in sentence structure, helping to convey meaning.\r",
    "wow**, **ouch**, **hey**\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Example Sentence:\r\n",
    "**\"The quick brown fox jumps over the lazy dog.\"**\r\n",
    "\r\n",
    "- **Noun**: **fox**, **dog**\r\n",
    "- **Pronoun**: None\r\n",
    "- **Verb**: **jumps**\r\n",
    "- **Adjective**: **quick**, **brown**, **lazy**\r\n",
    "- **Adverb**: None\r\n",
    "- **Preposition**: **over**\r\n",
    "- **Conjuncanding how words function within sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1157c6c1-62b3-4970-a198-cd950677239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"Natural language processing (NLP) is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and human languages. The ultimate goal of NLP is to enable machines to understand, interpret, and generate human language in a way that is both meaningful and useful. Techniques such as tokenization, part-of-speech tagging, and named entity recognition are commonly used in NLP applications. Despite the advances in NLP, challenges such as ambiguity, context, and language diversity still pose significant difficulties.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3739c33-5148-4eb6-9fee-70af7449f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "senteces = sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86c36f17-cb40-4236-8efa-47bca0933994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('subfield', 'VBD'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('(', '('), ('AI', 'NNP'), (')', ')'), ('focuses', 'VBZ'), ('interaction', 'JJ'), ('computers', 'NNS'), ('human', 'JJ'), ('languages', 'NNS'), ('.', '.')]\n",
      "[('The', 'DT'), ('ultimate', 'JJ'), ('goal', 'NN'), ('NLP', 'NNP'), ('enable', 'JJ'), ('machines', 'NNS'), ('understand', 'RB'), (',', ','), ('interpret', 'NN'), (',', ','), ('generate', 'VBP'), ('human', 'JJ'), ('language', 'NN'), ('way', 'NN'), ('meaningful', 'JJ'), ('useful', 'JJ'), ('.', '.')]\n",
      "[('Techniques', 'NNS'), ('tokenization', 'NN'), (',', ','), ('part-of-speech', 'JJ'), ('tagging', 'NN'), (',', ','), ('named', 'VBN'), ('entity', 'NN'), ('recognition', 'NN'), ('commonly', 'RB'), ('used', 'VBD'), ('NLP', 'NNP'), ('applications', 'NNS'), ('.', '.')]\n",
      "[('Despite', 'IN'), ('advances', 'NNS'), ('NLP', 'NNP'), (',', ','), ('challenges', 'VBZ'), ('ambiguity', 'NN'), (',', ','), ('context', 'NN'), (',', ','), ('language', 'NN'), ('diversity', 'NN'), ('still', 'RB'), ('pose', 'JJ'), ('significant', 'JJ'), ('difficulties', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(senteces)):\n",
    "    words = word_tokenize(senteces[i])\n",
    "    words = [word for word in words if word not in en_stopwords]\n",
    "    pos_tag = nltk.pos_tag(words)\n",
    "    print(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79d9a7-2d01-45d0-9242-44d72377a961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad4036cd-3bd0-4df0-9e72-102791154269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Taj', 'NNP'), ('Mahal', 'NNP'), ('is', 'VBZ'), ('beautiful', 'JJ'), ('monument', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "example = 'Taj Mahal is beautiful monument'\n",
    "\n",
    "print(nltk.pos_tag(example.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c254ac-e191-4663-925a-92b1ae1ab6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
