{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXMHNxXPR_7R",
        "outputId": "2bde59bd-4c00-445e-aba5-908e20307ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print('Hello World')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk scikeras -q"
      ],
      "metadata": {
        "id": "i4lFadetSH5J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Collection\n",
        "\n",
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "## loading data\n",
        "\n",
        "data = gutenberg.raw('shakespeare-hamlet.txt')\n",
        "\n",
        "## save as txt\n",
        "\n",
        "with open('hamlet.txt','w') as f:\n",
        "  f.write(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K6wVXPPSQBT",
        "outputId": "6eb3de2a-7717-4b9d-d8b4-be3d1801aa6d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Preprocessomg\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM,Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "metadata": {
        "id": "PJ9lCAf4S71l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('hamlet.txt','r') as f:\n",
        "  data = f.read().lower()\n",
        "\n",
        "## tokenize text\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "\n",
        "total_words = len(tokenizer.word_index)+1\n",
        "total_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LBeyU-OTb9P",
        "outputId": "014d0aff-e246-436c-89df-0041a6ab764c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4818"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create input list\n",
        "\n",
        "input_sequences = []\n",
        "\n",
        "for line in data.split('\\n'):\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1,len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "Pu02cHNyT0V9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ykOUOHscDT_",
        "outputId": "4fb2e5b0-352b-4b86-b144-c5d22615ccc9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 687],\n",
              " [1, 687, 4],\n",
              " [1, 687, 4, 45],\n",
              " [1, 687, 4, 45, 41],\n",
              " [1, 687, 4, 45, 41, 1886],\n",
              " [1, 687, 4, 45, 41, 1886, 1887],\n",
              " [1, 687, 4, 45, 41, 1886, 1887, 1888],\n",
              " [1180, 1889],\n",
              " [1180, 1889, 1890],\n",
              " [1180, 1889, 1890, 1891]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## pad sequences\n",
        "\n",
        "max_sequnece_len = max(len(x) for x in input_sequences)\n",
        "max_sequnece_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUmGUzvdcjzZ",
        "outputId": "588aaf1a-381f-469c-b046-5d8d6de3d35c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = np.array(pad_sequences(input_sequences,maxlen=max_sequnece_len,padding='pre'))\n",
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viAbtkp4c0-y",
        "outputId": "b5717f7b-23f4-4ca1-c82a-236e2f293965"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0,    1,  687],\n",
              "       [   0,    0,    0, ...,    1,  687,    4],\n",
              "       [   0,    0,    0, ...,  687,    4,   45],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    4,   45, 1047],\n",
              "       [   0,    0,    0, ...,   45, 1047,    4],\n",
              "       [   0,    0,    0, ..., 1047,    4,  193]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## create predicitors and label\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "x,y = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "y = tf.keras.utils.to_categorical(y,num_classes=total_words)"
      ],
      "metadata": {
        "id": "iO30dVKPc8-c"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=24)"
      ],
      "metadata": {
        "id": "kSaLaNAudaQa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## train our LSTM RNN\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "## Define Mode\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words,100,input_length=max_sequnece_len-1))\n",
        "model.add(LSTM(150, return_sequences=True))\n",
        "model.add(LSTM(100, return_sequences=True)) # Added return_sequences=True\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words,activation='softmax'))\n",
        "\n",
        "## Complile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "tIaxL1EpdnBN",
        "outputId": "0dd8052b-e35d-4c6f-ff2f-ac8fce91bf6a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Train the model\n",
        "\n",
        "history = model.fit(x_train,y_train,epochs=50,validation_data=(x_test,y_test),verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk1lDKHZeX0N",
        "outputId": "bf9d70cc-b100-4136-dec5-ad0bf8b4646a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - accuracy: 0.0299 - loss: 7.1615 - val_accuracy: 0.0325 - val_loss: 6.8268\n",
            "Epoch 2/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.0338 - loss: 6.5505 - val_accuracy: 0.0325 - val_loss: 6.8266\n",
            "Epoch 3/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.0386 - loss: 6.3844 - val_accuracy: 0.0395 - val_loss: 6.9061\n",
            "Epoch 4/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.0421 - loss: 6.3106 - val_accuracy: 0.0480 - val_loss: 6.9100\n",
            "Epoch 5/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.0469 - loss: 6.1631 - val_accuracy: 0.0460 - val_loss: 6.9094\n",
            "Epoch 6/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.0522 - loss: 6.0155 - val_accuracy: 0.0479 - val_loss: 6.9578\n",
            "Epoch 7/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.0555 - loss: 5.9289 - val_accuracy: 0.0524 - val_loss: 6.9779\n",
            "Epoch 8/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.0618 - loss: 5.7907 - val_accuracy: 0.0518 - val_loss: 7.0717\n",
            "Epoch 9/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.0687 - loss: 5.6561 - val_accuracy: 0.0535 - val_loss: 7.1600\n",
            "Epoch 10/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.0697 - loss: 5.5619 - val_accuracy: 0.0583 - val_loss: 7.2162\n",
            "Epoch 11/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.0747 - loss: 5.4848 - val_accuracy: 0.0519 - val_loss: 7.3169\n",
            "Epoch 12/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.0821 - loss: 5.3275 - val_accuracy: 0.0567 - val_loss: 7.3931\n",
            "Epoch 13/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.0850 - loss: 5.2175 - val_accuracy: 0.0605 - val_loss: 7.4653\n",
            "Epoch 14/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.0898 - loss: 5.1223 - val_accuracy: 0.0626 - val_loss: 7.6105\n",
            "Epoch 15/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.0970 - loss: 5.0528 - val_accuracy: 0.0589 - val_loss: 7.7271\n",
            "Epoch 16/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.1043 - loss: 4.9086 - val_accuracy: 0.0589 - val_loss: 7.8177\n",
            "Epoch 17/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1055 - loss: 4.8492 - val_accuracy: 0.0612 - val_loss: 7.9840\n",
            "Epoch 18/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.1096 - loss: 4.7447 - val_accuracy: 0.0600 - val_loss: 8.0934\n",
            "Epoch 19/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.1157 - loss: 4.6476 - val_accuracy: 0.0592 - val_loss: 8.2115\n",
            "Epoch 20/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1194 - loss: 4.5567 - val_accuracy: 0.0581 - val_loss: 8.3393\n",
            "Epoch 21/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1278 - loss: 4.4604 - val_accuracy: 0.0574 - val_loss: 8.4459\n",
            "Epoch 22/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.1341 - loss: 4.3676 - val_accuracy: 0.0570 - val_loss: 8.5731\n",
            "Epoch 23/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.1388 - loss: 4.2938 - val_accuracy: 0.0572 - val_loss: 8.7238\n",
            "Epoch 24/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.1493 - loss: 4.1782 - val_accuracy: 0.0544 - val_loss: 8.8394\n",
            "Epoch 25/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.1594 - loss: 4.1196 - val_accuracy: 0.0547 - val_loss: 8.9676\n",
            "Epoch 26/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.1700 - loss: 4.0389 - val_accuracy: 0.0564 - val_loss: 9.1069\n",
            "Epoch 27/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1799 - loss: 3.9861 - val_accuracy: 0.0536 - val_loss: 9.2319\n",
            "Epoch 28/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.2002 - loss: 3.8897 - val_accuracy: 0.0535 - val_loss: 9.3235\n",
            "Epoch 29/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.2039 - loss: 3.8444 - val_accuracy: 0.0567 - val_loss: 9.4440\n",
            "Epoch 30/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.2211 - loss: 3.7729 - val_accuracy: 0.0535 - val_loss: 9.6120\n",
            "Epoch 31/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.2260 - loss: 3.7006 - val_accuracy: 0.0505 - val_loss: 9.7237\n",
            "Epoch 32/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.2411 - loss: 3.6377 - val_accuracy: 0.0563 - val_loss: 9.8560\n",
            "Epoch 33/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.2571 - loss: 3.6005 - val_accuracy: 0.0535 - val_loss: 9.9398\n",
            "Epoch 34/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.2582 - loss: 3.5384 - val_accuracy: 0.0538 - val_loss: 10.0464\n",
            "Epoch 35/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.2617 - loss: 3.4949 - val_accuracy: 0.0502 - val_loss: 10.1400\n",
            "Epoch 36/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.2825 - loss: 3.4316 - val_accuracy: 0.0504 - val_loss: 10.2562\n",
            "Epoch 37/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.2736 - loss: 3.4040 - val_accuracy: 0.0511 - val_loss: 10.3308\n",
            "Epoch 38/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.2947 - loss: 3.3334 - val_accuracy: 0.0555 - val_loss: 10.4071\n",
            "Epoch 39/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.2930 - loss: 3.2964 - val_accuracy: 0.0507 - val_loss: 10.5267\n",
            "Epoch 40/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.3001 - loss: 3.2687 - val_accuracy: 0.0494 - val_loss: 10.5842\n",
            "Epoch 41/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.3193 - loss: 3.2017 - val_accuracy: 0.0511 - val_loss: 10.6723\n",
            "Epoch 42/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.3261 - loss: 3.1631 - val_accuracy: 0.0519 - val_loss: 10.7688\n",
            "Epoch 43/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.3328 - loss: 3.1278 - val_accuracy: 0.0515 - val_loss: 10.8576\n",
            "Epoch 44/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3435 - loss: 3.0766 - val_accuracy: 0.0522 - val_loss: 10.9314\n",
            "Epoch 45/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.3430 - loss: 3.0592 - val_accuracy: 0.0527 - val_loss: 10.9803\n",
            "Epoch 46/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.3528 - loss: 2.9908 - val_accuracy: 0.0532 - val_loss: 11.0696\n",
            "Epoch 47/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.3559 - loss: 2.9818 - val_accuracy: 0.0516 - val_loss: 11.1911\n",
            "Epoch 48/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.3728 - loss: 2.8957 - val_accuracy: 0.0515 - val_loss: 11.2105\n",
            "Epoch 49/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.3696 - loss: 2.8966 - val_accuracy: 0.0516 - val_loss: 11.3389\n",
            "Epoch 50/50\n",
            "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.3797 - loss: 2.8484 - val_accuracy: 0.0513 - val_loss: 11.3780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model, tokenizer, text, max_sequence_len):\n",
        "    # Tokenize the input text\n",
        "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "    # Pad the sequence\n",
        "    if len(token_list)>=max_sequence_len:\n",
        "        token_list = token_list[:max_sequence_len]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicated = model.predict(token_list, verbose=0)\n",
        "    predicted_word_index = np.argmax(predicated, axis=1)\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index==predicted_word_index:\n",
        "        return word\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "KoDrXCiieySS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"You come most\"\n",
        "max_sequnece_len= model.input_shape[1]+1\n",
        "nex_word = predict_next_word(model, tokenizer, input_text, max_sequnece_len)\n",
        "print(nex_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC9tJtz5iU1s",
        "outputId": "be499120-a8ce-44b4-aba7-8dc780021880"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "course\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "model.save('nex_word_lstm.h5')\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('tokenizer.pkl','wb') as f:\n",
        "  pickle.dump(tokenizer,f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuXy4-Y9igHE",
        "outputId": "229c405a-c8d3-476b-ac0f-468ae0773bbf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "iDLpF7s4jTYW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how to remove libararies from the requirements.txt which is not goona use in this file\n",
        "\n",
        "import os\n",
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM,Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "import pickle\n",
        "\n",
        "# ... (rest of your code)\n",
        "\n",
        "!pip freeze > requirements.txt\n",
        "!pip install -r requirements.txt  # Reinstall using the new requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4QvgwS9j0OE",
        "outputId": "27cbf382-01d2-4612-b3ff-abaadd5cb172"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cudf-cu12@ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.10.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (from -r requirements.txt (line 59))\n",
            "  Downloading https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.10.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (24.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting en-core-web-sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889 (from -r requirements.txt (line 89))\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hProcessing /colabtools/dist/google_colab-1.0.0.tar.gz (from -r requirements.txt (line 148))\n",
            "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/colabtools/dist/google_colab-1.0.0.tar.gz'\n",
            "\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5I8qJyEIkIec"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}